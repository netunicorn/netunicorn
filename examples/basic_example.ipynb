{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# netunicorn usage example\n",
    "This example shows basic client-side usage of netunicorn API.\n",
    "Prerequisites:\n",
    "- overall understanding of the project\n",
    "- deployed netunicorn infrastructure and director services\n",
    "- known `endpoint`, `login`, and `password` for the connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To work with the project, you need to install several packages:\n",
    "- `netunicorn-base` - provides abstractions and classes to create pipelines and define experiments. If you want to just define your pipeline and write tasks, you need only this package.\n",
    "- `netunicorn-client` - provides connectivity to netunicorn infrastructure. You need this package to submit and execute experiments.\n",
    "- `netunicorn-library` - a library of predefined and contributed tasks for the platform. You can use tasks in this package for your pipelines, and submit your code here to share. Please note, that most of the tasks there are provided 'as-is' by other teams and developers, and netunicorn team doesn't guarantee their correctness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: netunicorn-base in /home/kell/miniconda3/envs/netunicorntest/lib/python3.8/site-packages (0.3.0)\n",
      "Requirement already satisfied: typing-extensions in /home/kell/miniconda3/envs/netunicorntest/lib/python3.8/site-packages (from netunicorn-base) (4.5.0)\n",
      "Requirement already satisfied: returns in /home/kell/miniconda3/envs/netunicorntest/lib/python3.8/site-packages (from netunicorn-base) (0.20.0)\n",
      "Requirement already satisfied: pydantic in /home/kell/miniconda3/envs/netunicorntest/lib/python3.8/site-packages (from netunicorn-base) (1.10.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: netunicorn-client in /home/kell/miniconda3/envs/netunicorntest/lib/python3.8/site-packages (0.3.0)\n",
      "Requirement already satisfied: returns in /home/kell/miniconda3/envs/netunicorntest/lib/python3.8/site-packages (from netunicorn-client) (0.20.0)\n",
      "Requirement already satisfied: netunicorn-base>=0.3.0 in /home/kell/miniconda3/envs/netunicorntest/lib/python3.8/site-packages (from netunicorn-client) (0.3.0)\n",
      "Requirement already satisfied: cloudpickle in /home/kell/miniconda3/envs/netunicorntest/lib/python3.8/site-packages (from netunicorn-client) (2.2.1)\n",
      "Requirement already satisfied: requests in /home/kell/miniconda3/envs/netunicorntest/lib/python3.8/site-packages (from netunicorn-client) (2.30.0)\n",
      "Requirement already satisfied: typing-extensions in /home/kell/miniconda3/envs/netunicorntest/lib/python3.8/site-packages (from netunicorn-base>=0.3.0->netunicorn-client) (4.5.0)\n",
      "Requirement already satisfied: pydantic in /home/kell/miniconda3/envs/netunicorntest/lib/python3.8/site-packages (from netunicorn-base>=0.3.0->netunicorn-client) (1.10.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/kell/miniconda3/envs/netunicorntest/lib/python3.8/site-packages (from requests->netunicorn-client) (2023.5.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/kell/miniconda3/envs/netunicorntest/lib/python3.8/site-packages (from requests->netunicorn-client) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/kell/miniconda3/envs/netunicorntest/lib/python3.8/site-packages (from requests->netunicorn-client) (2.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/kell/miniconda3/envs/netunicorntest/lib/python3.8/site-packages (from requests->netunicorn-client) (3.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: netunicorn-library in /home/kell/miniconda3/envs/netunicorntest/lib/python3.8/site-packages (0.2.4)\n",
      "Requirement already satisfied: netunicorn-base>=0.2.5 in /home/kell/miniconda3/envs/netunicorntest/lib/python3.8/site-packages (from netunicorn-library) (0.3.0)\n",
      "Requirement already satisfied: pydantic in /home/kell/miniconda3/envs/netunicorntest/lib/python3.8/site-packages (from netunicorn-base>=0.2.5->netunicorn-library) (1.10.7)\n",
      "Requirement already satisfied: typing-extensions in /home/kell/miniconda3/envs/netunicorntest/lib/python3.8/site-packages (from netunicorn-base>=0.2.5->netunicorn-library) (4.5.0)\n",
      "Requirement already satisfied: returns in /home/kell/miniconda3/envs/netunicorntest/lib/python3.8/site-packages (from netunicorn-base>=0.2.5->netunicorn-library) (0.20.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install netunicorn-base\n",
    "%pip install netunicorn-client\n",
    "%pip install netunicorn-library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import needed classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%reload_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "# client to connect to the infrastructure\n",
    "from netunicorn.client.remote import RemoteClient\n",
    "\n",
    "# basic abstraction for experiment creation and management\n",
    "from netunicorn.base.experiment import Experiment, ExperimentStatus\n",
    "from netunicorn.base.pipeline import Pipeline\n",
    "\n",
    "# task to be executed in the pipeline\n",
    "# you can write your own tasks, but now let's use simple predefined one\n",
    "from netunicorn.library.tasks.basic import SleepTask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first, we want to define pipeline to execute. Pipeline consists of tasks located on different stages, and would be executed by each node where it would be assigned later.\n",
    "To creeate pipeline, instantiate Pipeline object and use command `.then()` to define a new stage. All tasks on the same stage would be started together, and the next stage would start only when all tasks from the current stage successfully finished."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# we will use simple SleepTask for this example\n",
    "# you can look at the source code of the SleepTaskLinuxImplementation to understand how it works\n",
    "\n",
    "pipeline = Pipeline()\n",
    "\n",
    "# Notice, that executor will first in parallel execute `sleep 5` and `sleep 3`...\n",
    "pipeline = pipeline.then([\n",
    "    SleepTask(5),\n",
    "    SleepTask(3)\n",
    "]).then(\n",
    "    # ...and after they finished (after 5 second in total) will execute `sleep 10`\n",
    "    SleepTask(10)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can combine multiple tasks and stages to create your own pipeline. Each instance of a task in a pipeline would be serialized (together with all parameters) and sent to the executor. The result of task (and pipeline in general) execution would be serialized and sent back to you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment is defined as one or multiple assignments of pipelines to particular nodes. To define the experiment, we should receive available nodes in infrastructure.\n",
    "\n",
    "To access the infrastructure, you need the next known parameters, provided by netunicorn installation administrators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# API connection endpoint\n",
    "endpoint = os.environ['NETUNICORN_ENDPOINT']\n",
    "\n",
    "# user login\n",
    "login = os.environ['NETUNICORN_LOGIN']\n",
    "\n",
    "# user password\n",
    "password = os.environ['NETUNICORN_PASSWORD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's create a client with these parameters\n",
    "client = RemoteClient(endpoint=endpoint, login=login, password=password)\n",
    "client.healthcheck()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using client, you can receive information about available nodes, and then filter them and take needed amount for your experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[snl-server-5, atopnuc-84:47:09:16:b6:cf, atopnuc-84:47:09:17:c2:14]\n",
      "Name: snl-server-5, properties: {'location': '', 'osarch': 'amd64', 'kernel': 'Linux', 'ipv4': ['10.0.10.1', '127.0.0.1', '128.111.5.231', '172.17.0.1', '172.18.0.1', '172.29.0.1'], 'network_type': 'public', 'ip_interfaces': {'lo': ['127.0.0.1', '::1'], 'eno1': ['128.111.5.231', 'fe80::ae1f:6bff:fe0b:69b4'], 'eno2': [], 'enp216s0f0': [], 'enp216s0f1': [], 'enp217s0f0': [], 'enp217s0f1': [], 'docker0': ['172.17.0.1', 'fe80::42:35ff:fed7:6ba3'], 'docker_gwbridge': ['172.18.0.1', 'fe80::42:21ff:fe0e:6f2f'], 'br-f7ff774e2075': ['172.29.0.1'], 'veth5bfc782': ['fe80::f824:22ff:fe9a:a9b'], 'br-0fca45465901': ['10.0.10.1', 'fe80::42:3eff:fef0:8e24'], 'veth4b64333': ['fe80::5cd9:e4ff:fea6:76a2'], 'vethb4b02e3': ['fe80::ac1c:6cff:fe10:d2a7']}, 'connector': 'salt'}\n",
      "Name: atopnuc-84:47:09:16:b6:cf, properties: {'location': '', 'osarch': 'amd64', 'kernel': 'Linux', 'ipv4': ['10.1.1.161', '127.0.0.1', '172.17.0.1', '172.18.0.1'], 'network_type': 'private', 'ip_interfaces': {'lo': ['127.0.0.1', '::1'], 'enp1s0': ['10.1.1.161', 'fe80::8647:9ff:fe16:b6cf'], 'wlo1': [], 'docker0': ['172.17.0.1', 'fe80::42:1dff:fee5:1a79'], 'docker_gwbridge': ['172.18.0.1', 'fe80::42:c5ff:feed:81d5'], 'veth2d42b44': ['fe80::78f0:8cff:fe5b:fe4e']}, 'connector': 'salt'}\n",
      "Name: atopnuc-84:47:09:17:c2:14, properties: {'location': '', 'osarch': 'amd64', 'kernel': 'Linux', 'ipv4': ['10.1.1.167', '127.0.0.1', '172.17.0.1', '172.18.0.1'], 'network_type': 'private', 'ip_interfaces': {'lo': ['127.0.0.1', '::1'], 'enp1s0': ['10.1.1.167', 'fe80::8647:9ff:fe17:c214'], 'wlo1': [], 'docker0': ['172.17.0.1'], 'docker_gwbridge': ['172.18.0.1', 'fe80::42:e5ff:fe27:ac8b'], 'veth4ecaf0e': ['fe80::3854:7aff:fec5:13ae']}, 'connector': 'salt'}\n"
     ]
    }
   ],
   "source": [
    "# let's receive all available for us nodes...\n",
    "nodes = client.get_nodes()\n",
    "\n",
    "# ... and take first 3 from the list\n",
    "nodes = nodes.take(3)\n",
    "\n",
    "# Each node object is a class with additional properties and information\n",
    "# You don't have to use it, but you can to better target your experiments and pipelines\n",
    "print(nodes)\n",
    "for node in nodes:\n",
    "    print(f\"Name: {node.name}, properties: {node.properties}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity, our first experiment would consist of 3 nodes running the same pipeline. Let's create Experiment instance and add all 3 nodes with the pipeline using `map()` method. You can read the documentation about other methods of creating assignments (called `Deployments` in netunicorn)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Deployment: Node=snl-server-5, executor_id=, prepared=False>; <Deployment: Node=atopnuc-84:47:09:16:b6:cf, executor_id=, prepared=False>; <Deployment: Node=atopnuc-84:47:09:17:c2:14, executor_id=, prepared=False>\n",
      "\n",
      "snl-server-5\n",
      "DockerImage(commands=[], image=None, build_context=BuildContext(python_version='3.8.0', cloudpickle_version='2.2.1'), runtime_context=RuntimeContext(ports_mapping={}, environment_variables={}, additional_arguments=[]))\n",
      "\n",
      "atopnuc-84:47:09:16:b6:cf\n",
      "DockerImage(commands=[], image=None, build_context=BuildContext(python_version='3.8.0', cloudpickle_version='2.2.1'), runtime_context=RuntimeContext(ports_mapping={}, environment_variables={}, additional_arguments=[]))\n",
      "\n",
      "atopnuc-84:47:09:17:c2:14\n",
      "DockerImage(commands=[], image=None, build_context=BuildContext(python_version='3.8.0', cloudpickle_version='2.2.1'), runtime_context=RuntimeContext(ports_mapping={}, environment_variables={}, additional_arguments=[]))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "experiment = Experiment().map(pipeline, nodes)\n",
    "\n",
    "# let's explore experiment object\n",
    "print(experiment)\n",
    "print()\n",
    "for deployment in experiment:\n",
    "    print(deployment.node)\n",
    "    print(deployment.environment_definition)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To submit the experiment, we need to create a user-wide unique name for the experiment, and call an appropriate method of the `client` object. Notice, that you can submit the same experiment several times with different names to be executed more than once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'experiment_cool_name'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_name = 'experiment_cool_name'\n",
    "try:\n",
    "    # just in case you already have this experiment\n",
    "    client.delete_experiment(experiment_name)\n",
    "except netunicorn.client.RemoteClientException as e:\n",
    "    # if not, exception would be fired\n",
    "    pass\n",
    "\n",
    "client.prepare_experiment(experiment, experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you submit an experiment, netunicorn services automatically create or download a virtual environment for execution of the pipeline, insert serialized pipeline inside and distribute these environments to the desired nodes.\n",
    "\n",
    "To check status of the experiment, you can use corresponding method of the `client` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExperimentStatus.PREPARING\n",
      "ExperimentStatus.PREPARING\n",
      "ExperimentStatus.PREPARING\n",
      "ExperimentStatus.PREPARING\n",
      "ExperimentStatus.PREPARING\n",
      "ExperimentStatus.PREPARING\n",
      "ExperimentStatus.PREPARING\n",
      "ExperimentStatus.PREPARING\n",
      "ExperimentStatus.PREPARING\n",
      "ExperimentStatus.READY\n"
     ]
    }
   ],
   "source": [
    "# status will change from PREPARING to READY when compiled and deployed\n",
    "while True:\n",
    "    info = client.get_experiment_status(experiment_name)\n",
    "    print(info.status)\n",
    "    if info.status == ExperimentStatus.READY:\n",
    "        break\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "snl-server-5\n",
      "True\n",
      "None\n",
      "\n",
      "atopnuc-84:47:09:16:b6:cf\n",
      "True\n",
      "None\n",
      "\n",
      "atopnuc-84:47:09:17:c2:14\n",
      "True\n",
      "None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# One of the returned objects is a prepared experiment. It holds all the information about deployments compilation\n",
    "# Some nodes could be failed to prepare due to various reasons\n",
    "prepared_experiment = info.experiment\n",
    "for deployment in prepared_experiment:\n",
    "    print(deployment.node)\n",
    "    print(deployment.prepared)\n",
    "    print(deployment.error)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the status is ready, nodes are prepared for execution and downloaded all the needed environments and pipelines (don't forget to check `prepared` status of the returned experiment to confirm).\n",
    "\n",
    "Now you can ask `client` object to start the experiment. It will ask nodes to spin up executors and will collect the execution results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'experiment_cool_name'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.start_execution(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExperimentStatus.RUNNING\n",
      "ExperimentStatus.RUNNING\n",
      "ExperimentStatus.RUNNING\n",
      "ExperimentStatus.RUNNING\n",
      "ExperimentStatus.RUNNING\n",
      "ExperimentStatus.FINISHED\n"
     ]
    }
   ],
   "source": [
    "# Again, let's check experiment status until it changes from RUNNING to FINISHED\n",
    "import time\n",
    "while True:\n",
    "    info = client.get_experiment_status(experiment_name)\n",
    "    print(info.status)\n",
    "    if info.status != ExperimentStatus.RUNNING:\n",
    "        break\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "<Success: defaultdict(<class 'list'>, {'3f319ac1-cd07-477b-9002-078c70cd3759': [<Success: 5>], '7fd0c06e-ad09-4697-b45f-d0f598bf5a6a': [<Success: 3>], 'dfa5ab53-a3ad-474f-9a78-8d13debd87c4': [<Success: 10>]})>\n",
      "['Parsed configuration: Gateway located on https://pinot.cs.ucsb.edu/dev/netunicorn/gateway\\n', 'Current directory: /\\n', 'Pipeline loaded from local file, executing.\\n', 'Pipeline finished, start reporting results.\\n']\n",
      "\n",
      "None\n",
      "<Success: defaultdict(<class 'list'>, {'3f319ac1-cd07-477b-9002-078c70cd3759': [<Success: 5>], '7fd0c06e-ad09-4697-b45f-d0f598bf5a6a': [<Success: 3>], 'dfa5ab53-a3ad-474f-9a78-8d13debd87c4': [<Success: 10>]})>\n",
      "['Parsed configuration: Gateway located on https://pinot.cs.ucsb.edu/dev/netunicorn/gateway\\n', 'Current directory: /\\n', 'Pipeline loaded from local file, executing.\\n', 'Pipeline finished, start reporting results.\\n']\n",
      "\n",
      "None\n",
      "<Success: defaultdict(<class 'list'>, {'3f319ac1-cd07-477b-9002-078c70cd3759': [<Success: 5>], '7fd0c06e-ad09-4697-b45f-d0f598bf5a6a': [<Success: 3>], 'dfa5ab53-a3ad-474f-9a78-8d13debd87c4': [<Success: 10>]})>\n",
      "['Parsed configuration: Gateway located on https://pinot.cs.ucsb.edu/dev/netunicorn/gateway\\n', 'Current directory: /\\n', 'Pipeline loaded from local file, executing.\\n', 'Pipeline finished, start reporting results.\\n']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for report in info.execution_result:\n",
    "    print(report.error)\n",
    "    result, log = report.result\n",
    "    print(result)\n",
    "    print(log)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congrats! We (hope, you too ^_^) successfully finished the basic experiment using the netunicorn platform.\n",
    "For next steps, you can read the documentation on creating more complex experiments, including writing your own tasks, providing your own Docker containers, experiment synchronization, etc.\n",
    "\n",
    "For all questions, refer to the official organization: https://github.com/netunicorn and netunicorn team."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "netunicorntest",
   "language": "python",
   "name": "netunicorntest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
